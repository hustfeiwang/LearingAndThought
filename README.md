# LearingAndThought

## [Scala Future & Thread](https://turbofei.github.io/coding/2019/05/19/scala-concurrent-programming-Future-And-Thread)

Scala中的Future与Thread详解.

- 日期: 2019-05-19

## [Scala Promise & ForkJoinPool](https://turbofei.github.io/coding/2019/05/18/scala-concurrent-programing-Promise-And-ForkJoinPool)

- 日期: 2019-05-19

## [About Maven](https://turbofei.github.io/coding/2019/05/19/About-Maven)

- 日期: 2019-05-19

## [Spark Sql Catalyst](https://turbofei.github.io/spark/2018/08/01/spark-sql-catalyst)

Catalyst分析报告

- 开始日期: 2018-09-20
- 期望日期: 2018-09-23

## [Spark Sql CBO](https://turbofei.github.io/spark/2018/12/04/spark-cbo-code-analysis)

spark CBO原理分析。

- 开始日期: 2018-08-23
- 期望日期: 2018-08-27

## [Spark Sql 流程分析](https://turbofei.github.io/spark/2018/07/27/Spark-Sql-Analysis)

spark sql 源码流程分析
- 开始日期: 2018-08-06
- 期望日期: 2018-08-27

## [Spark External Shuffle Service](https://turbofei.github.io/spark/2018/12/10/spark-external-shuffle-service)

讲解一下什么是external shuffle service

- 开始日期： 2018-08-24
- 期望日期： 2018-08-26

## [Spark Core：RDD理解与解读](https://netease-bigdata.github.io/ne-spark-courseware/slides/spark_core/rdd_basics.html#1)

讲述了RDD的源码角度理解与Spark机制。
- 开始日期: 2018-07-26
- 期望日期: 2018-08-07

## [Spark 应用执行流程分析](https://turbofei.github.io/spark/2016/12/22/spark%E5%BA%94%E7%94%A8%E6%89%A7%E8%A1%8C%E6%B5%81%E7%A8%8B)

从最简单的spark应用WordCount入手，分析rdd链，分析job如何提交，task如何提交，从全局了解spark应用的执行流程。

- 开始日期: 2016-08-06
- 期望日期: 2016-08-27

  

## [Spark Shuffle 分析](https://turbofei.github.io/spark/2016/12/26/spark%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90Shuffle%E5%AE%9E%E7%8E%B0)

spark shuff部分是spark源码的重要组成部分，shuffle发生在stage的交界处，对于spark的性能有重要影响，源码更新后，spark的shuffle机制也不一样，本文分析spark2.0的shuffle实现。
- 开始日期: 2016-10-06
- 期望日期: 2016-10-27

  

## [Spark统一内存管理](https://turbofei.github.io/spark/2016/12/19/spark%E7%BB%9F%E4%B8%80%E5%86%85%E5%AD%98%E7%AE%A1%E7%90%86)

spark统一内存管理是spark1.6.0的新特性，是对shuffle memory 和 storage memory 进行统一的管理，打破了以往的参数限制。
- 开始日期: 2016-10-06
- 期望日期: 2016-10-27
- 状态:  完成

## [Spark内存预测](https://turbofei.github.io/spark/2016/12/26/spark%E5%86%85%E5%AD%98%E9%A2%84%E6%B5%8B)

spark是一个内存计算框架，因此内存是重要的资源，合理的使用的内存在spark应用在执行过程中非常重要。在使用内存的过程，spark会采用抽样的方法预测出所需要的内存，并预先分配内存。本文会就内存预测机制进行源码的解读。
- 开始日期: 2016-10-06
- 期望日期: 2016-10-27

## Spark Block管理



## Spark Shuffle



## Spark 通信

